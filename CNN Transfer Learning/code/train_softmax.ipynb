{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "BATCH_SIZE = 4\n",
    "NCPF = 32 #number of classes per file\n",
    "NUM_CLASSES = 1*32\n",
    "TRAIN_SAMPLES = 4\n",
    "MAX_TRAIN_SAMPLES = 16\n",
    "VAL_SAMPLES = 4\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "TYPE = 'block4_pool'\n",
    "BIN_DIR = '../data/cal_predictions/{0}/'.format(TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def only_used(train_data):\n",
    "    return np.concatenate([train_data[MAX_TRAIN_SAMPLES*i:MAX_TRAIN_SAMPLES*i+TRAIN_SAMPLES] for i in range(NCPF)])\n",
    "\n",
    "#load training and validation data\n",
    "train_data = only_used(np.load(open(BIN_DIR + 'train/{0}_{1}.npy'.format(0,NCPF),'rb')))\n",
    "val_data = np.load(open(BIN_DIR + 'validation/{0}_{1}.npy'.format(0,NCPF),'rb'))\n",
    "for i in range(1,NUM_CLASSES//NCPF):\n",
    "    new_train_data = only_used(np.load(open(BIN_DIR + 'train/{0}_{1}.npy'.format(i*NCPF,(i+1)*NCPF),'rb')))\n",
    "    new_val_data = np.load(open(BIN_DIR + 'validation/{0}_{1}.npy'.format(i*NCPF,(i+1)*NCPF),'rb'))\n",
    "    train_data = np.concatenate((train_data, new_train_data))\n",
    "    val_data = np.concatenate((val_data, new_val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create training labels\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "for c in range(NUM_CLASSES):\n",
    "    train_labels.extend([[0]*c + [1] + [0]*(NUM_CLASSES-c-1) for l in range(TRAIN_SAMPLES)])\n",
    "    val_labels.extend([[0]*c + [1] + [0]*(NUM_CLASSES-c-1) for l in range(VAL_SAMPLES)])\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle samples and labels\n",
    "train_perm = np.random.permutation(NUM_CLASSES*TRAIN_SAMPLES)\n",
    "val_perm = np.random.permutation(NUM_CLASSES*VAL_SAMPLES)\n",
    "train_data, train_labels = train_data[train_perm], train_labels[train_perm]\n",
    "val_data, val_labels = val_data[val_perm], val_labels[val_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "inp = Input( train_data.shape[1:] )\n",
    "out = Dense(NUM_CLASSES, activation='softmax')(inp)\n",
    "tl_model = Model( input=inp, output=out )\n",
    "tl_model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 128 samples\n",
      "Epoch 1/15\n",
      "128/128 [==============================] - 3s - loss: 15.4431 - acc: 0.0234 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 2/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 3/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 4/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 5/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 6/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 7/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 8/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 9/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 10/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 11/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 12/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 13/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 14/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n",
      "Epoch 15/15\n",
      "128/128 [==============================] - 2s - loss: 15.1107 - acc: 0.0625 - val_loss: 15.6144 - val_acc: 0.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b50f748>"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_model.fit(train_data, train_labels,\n",
    "             nb_epoch=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "             validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
