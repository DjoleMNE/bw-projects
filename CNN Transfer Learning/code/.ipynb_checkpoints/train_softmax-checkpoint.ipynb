{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "BATCH_SIZE = 2\n",
    "NCPF = 32 #number of classes per file\n",
    "NUM_CLASSES = 256\n",
    "TRAIN_SAMPLES = 16\n",
    "VAL_SAMPLES = 4\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "BIN_DIR = '../data/cal_predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load training and validation data\n",
    "train_data = np.load(open(BIN_DIR + 'train/{0}_{1}.npy'.format(0,NCPF),'rb'))\n",
    "validation_data = np.load(open(BIN_DIR + 'validation/{0}_{1}.npy'.format(0,NCPF),'rb'))\n",
    "for i in range(1,NUM_CLASSES//NCPF):\n",
    "    new_train_data = np.load(open(BIN_DIR + 'train/{0}_{1}.npy'.format(i*NCPF,(i+1)*NCPF),'rb'))\n",
    "    new_validation_data = np.load(open(BIN_DIR + 'validation/{0}_{1}.npy'.format(i*NCPF,(i+1)*NCPF),'rb'))\n",
    "    train_data = np.concatenate((train_data, new_train_data))\n",
    "    validation_data = np.concatenate((validation_data, new_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create training labels\n",
    "train_labels = []\n",
    "validation_labels = []\n",
    "for c in range(NUM_CLASSES):\n",
    "    train_labels.extend([[0]*c + [1] + [0]*(NUM_CLASSES-c-1) for l in range(TRAIN_SAMPLES)])\n",
    "    validation_labels.extend([[0]*c + [1] + [0]*(NUM_CLASSES-c-1) for l in range(VAL_SAMPLES)])\n",
    "train_labels = np.array(train_labels)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle samples and labels\n",
    "train_perm = np.random.permutation(NUM_CLASSES*TRAIN_SAMPLES)\n",
    "val_perm = np.random.permutation(NUM_CLASSES*VAL_SAMPLES)\n",
    "train_data, train_labels = train_data[train_perm], train_labels[train_perm]\n",
    "validation_data, validation_labels = validation_data[val_perm], validation_labels[val_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "inp = Input( train_data.shape[1:] )\n",
    "out = Dense(NUM_CLASSES, activation='softmax')(inp)\n",
    "tl_model = Model( input=inp, output=out )\n",
    "tl_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4096 samples, validate on 1024 samples\n",
      "Epoch 1/15\n",
      "4096/4096 [==============================] - 50s - loss: 0.0411 - acc: 0.9949 - val_loss: 0.0432 - val_acc: 0.9958\n",
      "Epoch 2/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0394 - acc: 0.9949 - val_loss: 0.0492 - val_acc: 0.9949\n",
      "Epoch 3/15\n",
      "4096/4096 [==============================] - 49s - loss: 0.0385 - acc: 0.9947 - val_loss: 0.0527 - val_acc: 0.9943\n",
      "Epoch 4/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0402 - acc: 0.9945 - val_loss: 0.0693 - val_acc: 0.9927\n",
      "Epoch 5/15\n",
      "4096/4096 [==============================] - 49s - loss: 0.0683 - acc: 0.9931 - val_loss: 0.0672 - val_acc: 0.9936\n",
      "Epoch 6/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0689 - acc: 0.9934 - val_loss: 0.0672 - val_acc: 0.9944\n",
      "Epoch 7/15\n",
      "4096/4096 [==============================] - 49s - loss: 0.0689 - acc: 0.9937 - val_loss: 0.0679 - val_acc: 0.9927\n",
      "Epoch 8/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0688 - acc: 0.9938 - val_loss: 0.0669 - val_acc: 0.9955\n",
      "Epoch 9/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0688 - acc: 0.9939 - val_loss: 0.0666 - val_acc: 0.9960\n",
      "Epoch 10/15\n",
      "4096/4096 [==============================] - 49s - loss: 0.0691 - acc: 0.9934 - val_loss: 0.0796 - val_acc: 0.9922\n",
      "Epoch 11/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0692 - acc: 0.9932 - val_loss: 0.0674 - val_acc: 0.9933\n",
      "Epoch 12/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0692 - acc: 0.9931 - val_loss: 0.0711 - val_acc: 0.9922\n",
      "Epoch 13/15\n",
      "4096/4096 [==============================] - 47s - loss: 0.0692 - acc: 0.9933 - val_loss: 0.0688 - val_acc: 0.9922\n",
      "Epoch 14/15\n",
      "4096/4096 [==============================] - 48s - loss: 0.0692 - acc: 0.9932 - val_loss: 0.0672 - val_acc: 0.9956\n",
      "Epoch 15/15\n",
      "4096/4096 [==============================] - 50s - loss: 0.0692 - acc: 0.9932 - val_loss: 0.0683 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119f2e4e0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "tl_model.fit(train_data, train_labels,\n",
    "          nb_epoch=15, batch_size=BATCH_SIZE,\n",
    "          validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
