{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import vgg16\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constants\n",
    "BATCH_SIZE = 4\n",
    "NCPF = 32 #number of classes per file\n",
    "TRAIN_SAMPLES = 16\n",
    "VAL_SAMPLES = 4\n",
    "\n",
    "STARTING_CLASS = 0*NCPF #change to the class we left off from\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "TYPE = 'block4_pool'\n",
    "BIN_DIR = '../data/cal_predictions/{0}/'.format(TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "vgg_model = vgg16.VGG16( weights='imagenet', include_top=True ) #downloads prebuilt\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "if TYPE == 'no_norm' or TYPE == 'norm':\n",
    "    vgg_out = vgg_model.layers[-2].output\n",
    "else:\n",
    "    vgg_out = vgg_model.get_layer(TYPE)\n",
    "    vgg_out = Flatten()(vgg_model.get_layer(TYPE).output)\n",
    "model = Model( input=vgg_model.input, output=vgg_out )\n",
    "model.compile( loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_45 (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_45[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 100352)        0           block4_pool[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 7,635,264\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,635,264\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(samplewise_center=False, samplewise_std_normalization=False)#standardizes per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4096 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "#create a generator for the training samples starting from the class we left off from\n",
    "generator = datagen.flow_from_directory(\n",
    "            DATA_DIR + 'train',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "for _ in range(STARTING_CLASS*TRAIN_SAMPLES//BATCH_SIZE): #skip up to the starting class\n",
    "    generator.next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Image.fromarray(np.uint8(generator.next()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = model.predict_generator(generator, TRAIN_SAMPLES*NCPF) #push through vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(open(BIN_DIR + 'train/{0}_{1}.npy'.format(STARTING_CLASS,STARTING_CLASS+NCPF), 'wb'), features) #save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "#create a generator for the validation samples starting from the class we left off from\n",
    "generator = datagen.flow_from_directory(\n",
    "            DATA_DIR + 'validation',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "for _ in range(STARTING_CLASS*VAL_SAMPLES//BATCH_SIZE): #skip up to the starting class\n",
    "    generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = model.predict_generator(generator, VAL_SAMPLES*NCPF) #push through vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(open(BIN_DIR + 'validation/{0}_{1}.npy'.format(STARTING_CLASS,STARTING_CLASS+NCPF), 'wb'), features) #save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
